{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML,clear_output\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xml.etree.ElementTree as ET \n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = 'data/training/'\n",
    "test_dir = 'data/test_1/'\n",
    "\n",
    "(winW, winH) = (64, 64) # Sliding window Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and parse files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_bounding_boxes(train_dir):\n",
    "    \"\"\"\n",
    "    Reads the annotation .xml files located in train_dir.\n",
    "    There is one file per training sample that and includes: path of the image im_path, bounding box coordinates (xmin,ymin)(xmax,ymax),\n",
    "    and bouding box label: label\n",
    "    \n",
    "    Returns: images_inside_box : List of all samples cropped at bouding box coordinates\n",
    "             labels : List of labels for all samples\n",
    "             images : Images (non cropped) for all samples\n",
    "    \n",
    "    \"\"\"\n",
    "    images_inside_box = [] # List of all samples cropped at bouding box coordinates\n",
    "    labels = [] # List of labels for all samples\n",
    "    images = [] # Images (non cropped) for all samples\n",
    "    for filename in sorted(os.listdir(train_dir)): # Reads files in train_dir\n",
    "        if not filename.endswith('.xml'): continue #For ex if it's jpeg \n",
    "        fullname = os.path.join(train_dir, filename)\n",
    "        tree = ET.parse(fullname)\n",
    "        im_path=tree.find('.//path').text #Tag path of .xml has image path\n",
    "        \n",
    "        for i,label in enumerate(tree.findall('.//name')): #Each sample may have more than one bounding box whose label        \n",
    "            xmin = int(tree.findall('.//xmin')[i].text)    #is described in .xml's name tag\n",
    "            ymin = int(tree.findall('.//ymin')[i].text)\n",
    "            xmax = int(tree.findall('.//xmax')[i].text)\n",
    "            ymax = int(tree.findall('.//ymax')[i].text)\n",
    "            label=label.text\n",
    "            try:\n",
    "                img = cv2.imread(im_path)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            im_bound = img[ymin:ymax,xmin:xmax]\n",
    "            im_bound = cv2.resize(im_bound, (0,0), fx=0.5, fy=0.5) #Resize the sample to half of its size \n",
    "            images_inside_box.append(im_bound)\n",
    "            img = cv2.resize(img, (0,0), fx=0.5, fy=0.5) \n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        \n",
    "    return images,images_inside_box,labels\n",
    "\n",
    "def get_test_imgs(test_imgs=test_dir):\n",
    "    \"\"\"\n",
    "    Gets test samples which are not annotated \n",
    "    Returns: test_images : list of test samples\n",
    "             list of test samples' path\n",
    "    \"\"\"\n",
    "    test_images = []\n",
    "    for img in sorted(os.listdir(test_imgs)):\n",
    "        img = cv2.imread(test_imgs+img)\n",
    "        img = cv2.resize(img, (0,0), fx=0.5, fy=0.5)\n",
    "        test_images.append(img)\n",
    "    return test_images,sorted(os.listdir(test_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cards Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cards_model:\n",
    "    \"\"\"\n",
    "    Class containing methods to preprocess, extract features, train and predict an image label\n",
    "    Input : bow_size : Number of words for the Bag-of-Words model\n",
    "            C : C hyperparamter for the model\n",
    "    \"\"\"\n",
    "    def __init__(self,bow_size=200,C=1):\n",
    "        self.bow_size=bow_size\n",
    "        self.dict_vectorizer=DictVectorizer()\n",
    "        self.sift_cluster = KMeans(self.bow_size)\n",
    "        self.dict_vect = None\n",
    "        self.C = C\n",
    "        self.model_number= LogisticRegression(C=self.C)\n",
    "        self.model_rank = SVC(C=self.C,probability=True,kernel='rbf',decision_function_shape='ovr')\n",
    "                \n",
    "    def desc_sift_img_list(self,images):\n",
    "        \"\"\"\n",
    "        This method extracts SIFT features from a list of images\n",
    "        Input : images : list of images\n",
    "        Return: imgs_desc : list of SIFT descriptors\n",
    "        \"\"\"\n",
    "        imgs_desc = []\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        for image in images:\n",
    "            _ , desc = sift.detectAndCompute(image, None)\n",
    "            imgs_desc.append(desc)\n",
    "        return imgs_desc\n",
    "        \n",
    "    def create_bow(self,list_desc):\n",
    "        \"\"\"\n",
    "        Creates a BoW from a list of descrpitors\n",
    "        Input: list_desc : List of descriptors\n",
    "        Return: List_bow: list of BoW disctionaries (one dictionary per sample)\n",
    "        \"\"\"\n",
    "        list_bow = []\n",
    "        for desc in list_desc:\n",
    "            bow=Counter((self.sift_cluster.predict(desc)))\n",
    "            list_bow.append(bow)\n",
    "        return list_bow\n",
    "    \n",
    "    def preprocessing(self,list_images):\n",
    "        \"\"\"\n",
    "        Preprocesses images\n",
    "        Input: list_images: List of images to be preprocessed\n",
    "        Return: preprocessed_imgs: List of preprocessed images\n",
    "        \"\"\"\n",
    "        preprocessed_imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in list_images]\n",
    "        return preprocessed_imgs\n",
    "        \n",
    "    def feature_extraction(self,images,train=False):\n",
    "        \"\"\"\n",
    "        Manages feature extraction by calling methods to extract SIFT descrpitors \n",
    "        and to create the Bag-of-Words description. If train mode is True then it also trains a k-means clustering model\n",
    "        used to cluster descriptors into words (for BoW)\n",
    "        \n",
    "        Input: images: list of images\n",
    "               train: boolean, True if is extracting features from training samples\n",
    "        Return: Vectorized Bow for each image\n",
    "        \n",
    "        \"\"\"\n",
    "        features = self.desc_sift_img_list(images)\n",
    "        \n",
    "        if train is True:\n",
    "            concat_im = np.concatenate(features)\n",
    "            self.sift_cluster.fit(concat_im)\n",
    "        \n",
    "        feat_dict = self.create_bow(features)\n",
    "        if train is True:\n",
    "            self.dict_vectorizer.fit(feat_dict) #Vectorize is required to work with scikit-learn API\n",
    "        \n",
    "        X = self.dict_vectorizer.transform(feat_dict)\n",
    "        return X\n",
    "    \n",
    "    def train(self,list_images,labels):\n",
    "        \"\"\"\n",
    "        Manages training process by calling preprocessing, feature extraction and model fit method.\n",
    "        Input: list_images: List of training samples\n",
    "               labels: List of training labels\n",
    "        Return: self.model_num: Model to classify a card number \n",
    "        \n",
    "        \"\"\"\n",
    "        preprocessed_imgs = self.preprocessing(list_images)\n",
    "        X = self.feature_extraction(preprocessed_imgs,train=True)\n",
    "        self.model_number.fit(X,labels)        \n",
    "        return self.model_number\n",
    "    \n",
    "    def predict(self,list_images):\n",
    "        \"\"\"\n",
    "        Predicts the number of a playing card\n",
    "        Input: list_images: List of images to classify\n",
    "        Return: prob_preds_number: list with model output for each class  (matrix without class names)\n",
    "                preds_number: list with most probable class\n",
    "        \"\"\"\n",
    "        preprocessed_imgs = self.preprocessing(list_images)\n",
    "        X = self.feature_extraction(preprocessed_imgs,train=False)\n",
    "        prob_preds_number = self.model_number.decision_function(X)\n",
    "        preds_number = self.model_number.predict(X)\n",
    "        return prob_preds_number,preds_number\n",
    "    \n",
    "    def predict_proba(self,list_images,threshold=0):\n",
    "        \"\"\"\n",
    "         Similar to predict but returns a list of model output for each class  that is above a given threshold\n",
    "         Input: list_images: images to be classified\n",
    "                threshold: confidence value above which a class is assigned to a sample\n",
    "                \n",
    "         Return: list with model output for each class that is above a threshold\n",
    "        \"\"\"\n",
    "        preds_number,_ = self.predict(list_images)\n",
    "        preds_number.argmax(axis=1)\n",
    "        return self.model_number.classes_[((preds_number > threshold) * preds_number).nonzero()[1]],preds_number[((preds_number > threshold) * preds_number).nonzero()]\n",
    "    \n",
    "    def show_predictions(self,list_images,image_names):\n",
    "        \"\"\"\n",
    "        Builds an interpretable table of predict method output\n",
    "        \"\"\"\n",
    "        preds_number,_ = self.predict(list_images)\n",
    "        preds_number_pd = pd.DataFrame(preds_number,index=image_names)\n",
    "        preds_number_pd.columns = self.model_number.classes_        \n",
    "        return preds_number_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyramid and Sliding window classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pyramid(image, scale=1.5, minSize=(30, 30)):\n",
    "    \"\"\"\n",
    "    Build pyramid images from an orginal sample\n",
    "    Input: scale: Factor by which previous image's dimensions are decreased\n",
    "           minSize: Size of the smallest pyramid desired\n",
    "    Return: pyramid_images: Set of pyramid images\n",
    "    \"\"\"\n",
    "    # yield the original image\n",
    "    pyramid_images=[]\n",
    "    #yield image\n",
    "    pyramid_images.append(image)\n",
    "    # keep looping over the pyramid\n",
    "    while True:\n",
    "        # compute the new dimensions of the image and resize it\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    "\n",
    "            # if the resized image does not meet the supplied minimum\n",
    "            # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            #break\n",
    "             return pyramid_images   \n",
    "            # yield the next image in the pyramid\n",
    "        pyramid_images.append(image)\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    \"\"\"\n",
    "    Slides a window across an image. \n",
    "    Input: image: image from which windows are created\n",
    "           stepSize: distance between the initial coordinates of consecutive windows\n",
    "           windowSize: size of each window\n",
    "    Return: List of top left corner coordinates for each window and window values\n",
    "    \"\"\"\n",
    "    # slide a window across the image\n",
    "    sliding_windows=[]\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            sliding_windows.append((x, y, image[y:y + windowSize[1], x:x + windowSize[0]]))\n",
    "    return sliding_windows\n",
    "\n",
    "def slide(image,cm,threshold=0):\n",
    "    \"\"\"\n",
    "    Calls the classification model for each window of each image pyramide.\n",
    "    Input: image: image to be classified\n",
    "           cm: a trained instance of cards model\n",
    "           threshold: threshold value for predict_proba method\n",
    "    Return: dict_results: Dictionary with highest confidence for each class that is above threshold\n",
    "    \"\"\"\n",
    "    maxVal = [('A',0)]\n",
    "    results = []\n",
    "    dict_results = {}\n",
    "    # loop over the image pyramid\n",
    "    for resized in pyramid(image, scale=1.5):\n",
    "        # loop over the sliding window for each layer of the pyramid\n",
    "        for (x, y, window) in sliding_window(resized, stepSize=32, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "\n",
    "            sift = cv2.xfeatures2d.SIFT_create()\n",
    "            _ , desc = sift.detectAndCompute(window, None)\n",
    "            if desc is None:\n",
    "                continue\n",
    "            result = cm.predict_proba([window],threshold)\n",
    "\n",
    "            \n",
    "            if len(result[0])>0:\n",
    "                    results.append(result)\n",
    "                   \n",
    "\n",
    "    for (i,j) in results:\n",
    "        try:\n",
    "            if dict_results.get(i[0]) < float(j):\n",
    "                dict_results[i[0]]=float(j)\n",
    "        except:\n",
    "            dict_results[i[0]]=float(j)\n",
    "    return dict_results\n",
    "\n",
    "def classification(images,templates,true_labels):\n",
    "    \"\"\"\n",
    "    Classification main function. Creates model and sequentially tries to predict an image number.\n",
    "    Input: images:list of images to be predicted\n",
    "           templates: training samples (bouding boxes)\n",
    "           true_labels: training samples' labels\n",
    "    Return: list of dictionaries with predicitions for each sample\n",
    "    \"\"\"\n",
    "    pred_labels=[]\n",
    "    cm = cards_model()\n",
    "    cm.train(templates,true_labels)\n",
    "    for curr_img in images:\n",
    "        result = slide(curr_img,cm,0.2)\n",
    "        pred_labels.append(result)\n",
    "    return pred_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'A': 0.3707178829773894, 'J': 0.8959318908880727},\n",
       " {'3': 1.0726528794274481},\n",
       " {'A': 0.4966758878180517},\n",
       " {'A': 0.29429054659620846, 'J': 0.34950286789645557},\n",
       " {'2': 0.9630108563637132},\n",
       " {'2': 1.7715881259839132, '3': 0.37703565327372845, 'A': 0.390655018345365},\n",
       " {'2': 1.7715881259839132, '3': 0.37703565327372845, 'A': 0.390655018345365},\n",
       " {'2': 1.7715881259839132, '3': 0.37703565327372845, 'A': 0.390655018345365},\n",
       " {'Q': 1.0876830045549932},\n",
       " {'A': 1.9096374032787855},\n",
       " {},\n",
       " {'Q': 0.9103675618113347},\n",
       " {'A': 1.4301655917811753},\n",
       " {'5': 0.33280035004333874},\n",
       " {'10': 0.5396707452847671, 'K': 1.1911560542830453},\n",
       " {'7': 1.005807583520719, '8': 0.2630632227491039},\n",
       " {'7': 1.005807583520719, '8': 0.2630632227491039}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_im,_ = get_test_imgs()\n",
    "im,templates,la=open_bounding_boxes(train_dir)\n",
    "results = classification(im,templates,la)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
